---
title: "MEPS_IBTS_1"
author: "Andrew Edwards"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{MEPS_IBTS_1}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 6,
  fig.height = 6
)
```

```{r setup}
library(sizeSpectra)
```

# Pre-processing of IBTS data

This vignette steps through the pre-processing steps of the IBTS data as presented in the
MEPS paper to retain just the desired parts. May be useful for anyone wanting to
extract data and do similar analyses.

```{r}
library(sizeSpectra)
```

<!-- From nSeaFungImport.Snw:-->

Data extracted from IBTS DATRAS website TODO: copy details from paper. This may
already include some extra steps from Julia - check her earlier code. Fairly sure a
and b are from Fung et al. (I have that .csv file also).


```{r, eval=FALSE}
# This is done in package in data-raw/IBTS-data.R to save the data more
#  efficiently as dataOrig within the package. Code is not evaluated here.
load("ibtsQ1cpuelength.RData") # 2.2 Mb dataset, just contains
                               #  "q1" which is a data.frame
dataOrig = tbl_df(q1)        # for dplyr
```

Understand the raw data:
```{r}
dim(dataOrig)
names(dataOrig)
dataOrig[1:5,1:7]
dataOrig[1:5,8:13]

summary(dataOrig)
```

Note that 'LngtClas' is in mm, not cm, but that 'a' and 'b' are the length-weight coefficients for the length being in cm. Will use cm as units later.

Some columns are duplicated and we just want to keep the useful ones. 'AphiaID'
is a numerical code for each species. Need to know the number of areas, but
don't need to keep 'Area'.

Want to end up with a data frame of the same format as in {\tt
  nSea15import.Snw}, since then presumably the {\tt nSea15analysis.Snw} code
will not need too much modification to work on this new data set. {\tt Survey}
and {\tt Quarter} are the same for all entries, and I don't need to keep {\tt
  Area}, just need the number of areas.

```{r}
numAreas = length(unique(dataOrig$Area))
numAreas
colsKeep = c("Year",
             "AphiaID",
             "LngtClas",
             "CPUE_number_per_hour",
             "a",
             "b",
             "weight_g",
             "CPUE_bio_per_hour")
colsDiscard = setdiff(names(dataOrig), colsKeep)
colsDiscard
```

Note that `data` will change a lot in the following code.

```{r}
data = s_select(dataOrig, colsKeep)   # uses Sebastian Kranz's s_dplyr_funcs.r
data
# str(data)
summary(data)
min(data$CPUE_number_per_hour)
```

So no negative CPUE values or spurious weights. There are a lot of zero CPUE values:
```{r}
sum(data$CPUE_number_per_hour == 0)
```

Want to end up with `data` in a standard format (based on some original
analysis). Need to rename some of the headings, make the lengths in cm not mm,
and (for helpfulness) order by `Year`, `SpecCode` and then `Lgnt`.

1. Rename the columns:
```{r rename}
if(sum( colsKeep != c("Year", "AphiaID", "LngtClas", "CPUE_number_per_hour",
    "a", "b", "weight_g", "CPUE_bio_per_hour")) > 0)
       { stop("Need to adjust renaming") }
names(data) = c("Year", "SpecCode", "LngtClass", "Number", "LWa", "LWb",
         "bodyMass", "CPUE_bio_per_hour")
# CPUE_bio_per_hour is Number * bodyMass
```

2. Make cm not mm:
```{r cm}
data$LngtClass = data$LngtClass/10
```

3. Rearrange the order to be more intuitive:
```{r arrange}
data = dplyr::arrange(data, Year, SpecCode, LngtClass)
data
```

That shows that we have a lot of (i) repeated values that can be amalgamated
(presumably repeated because at one point the data included details about
trawls, or it's just how the data were obtained), (ii) lots of `Number == 0`
that we can discard, though keep for now since will help verify the binning.

(i) So, each row represents a combination of `Year, SpecCode, LngtClass`, but
these aren't unique. For example, looking at just one species for one year for
one length class:
```{r}
exampleSp = dplyr::filter(data, Year == 1986, SpecCode == 105814, LngtClass == 60)
exampleSp
```
So, yes, we have multiple counts of 60cm fish of this species, which we can just aggregate together. Do this for all years, species and lengths:

```{r, aggregating}
data = dplyr::summarise(dplyr::group_by(data,
                                        Year,
                                        SpecCode,
                                        LngtClass),
                        "Number" = sum(Number)/numAreas,
                        "LWa" = unique(LWa),
                        "LWb" = unique(LWb),
                        "bodyMass" = unique(bodyMass))
data
summary(data)

dplyr::filter(data, SpecCode == 105814, Year == 1986, LngtClass == 60)
```
So `Number` here correctly equals the sum of the first two rows of `exampleSp`
divided by seven (areas).

So {\tt Number} is the average number (of each species and length) caught per
hour of trawling across all seven areas.

Just confirm the calculations for `bodyMass` (body mass of an individual of that
`LngtClass`) since they were done during preprocessing;
should get the same answer, using species-specific length-weight coversions.
```{r, bodyMass}
data = dplyr::mutate(data,
                     bodyMass2 = LWa * LngtClass^LWb)
if(max(abs(data$bodyMass2 - data$bodyMass)) > 0.0001) stop("Check conversions")
data = dplyr::select(data, -bodyMass2)              # don't keep the confirming column
```



Blanchard et al.~(2005) only included body-mass classes above 4~g. Do that here (since presumably data are noisy for smaller organisms):
<<>>=
range(data$LngtClass)
range(data$bodyMass)
sum(data$bodyMass == 0)   # 2549
sum(data$bodyMass < 4 )   # 6893
data = dplyr::filter(data, bodyMass >= 4)
range(data$bodyMass)
data
summary(data)

# Total number of fish in this dataset is:
sum(data$Number)
@

The unique length classes are:
<<lengths>>=
sort(unique(data$LngtClass))
diff(sort(unique(data$LngtClass)))
@

I think they may change over the years, which will become apparent in the figure to be constructed in {\tt nSeaFungAnalysis.Snw}, which will load in this {\tt data} dataframe.

Saving {\tt data} so this file does not need to be re-run:

<<saveData>>=
save(data, file="nSeaFungImport.RData")
@

\end{document}


-----------------------------------





From nSeaFungAnalysis.Snw - entire thing:

Initial pre-processing has already been done, so:
<<>>=

if(redo.eight)
  { load("nSeaFungImport.RData")
    stop("check results end up the same since I've now added the ungroup(data)
          below and haven't re-run before. Then delete this line.")
    } else
  { load("nSeaFungAnalysis.RData")
    redo.eight=FALSE }         # else it loads in previous, which can be TRUE.
source("../../../fitting-size-spectra/code/PLBfunctions.r")

data = ungroup(data)           # otherwise groups carry on.
data
summary(data)
@

The local data frame {\tt data} has a unique row for every combination of year, species code and length class, as checked by:
<<>>=
unique = dim(summarise(group_by(data, Year, SpecCode, LngtClass), count=n()))[1]
unique
if( unique != dim(data)[1]) stop("something wrong with 'data'")
@

The `Number' column in {\tt data} is the number of observed individuals of that species in that length class in that year. `bodyMass' is the body mass of such an individual, as calculated by {\tt LWa * LngtClass$^{{\tt LWb}}$} in {\tt nSeaFungImport.Snw} (and by Julia).

<<dataSumm, echo=FALSE, results=hide>>=
dataSumm = summarise(group_by(data, Year),
    uniqLngtClass = length(unique(LngtClass)),
    uniqSpec = length(unique(SpecCode)),
    medNumber = median(Number), medBodyMass = median(bodyMass))
@


<<defineFunction, echo=FALSE, results=hide>>=
dataSummTab = xtable(round(dataSumm), caption="Summary of the data available
  for each year. For each year, `uniqLngtClass' is the number of unique
  length classes, `uniqSpec' is the number of unique species, `medNumber'
  is the median number of individuals (where `Number' is length-class-specific
  and species-specific), and `medBodyMass' is the median body mass (where
  body mass is also length-class-specific and species-specific). All values
  rounded to nearest integer (which is why `medNumber' comes out all 0, since
  it's per hour, not an integer).",
  lab="tab:dataSumm", digits = 0)    # Number of digits after decimal

postscript("dataSumm.eps", height = figheight/1.5, width = figwidth,
           horizontal=FALSE,  paper="special")

par(omi = c(0.14, 0, 0.1, 0.15))      # outer margins in inches
par(mfrow=c(2,2)) #7,1))

oldmai = par("mai")    #   0.6732 0.5412 0.5412 0.2772  inches I think,
                       #    may be indpt of fig size
par(mai=c(0.3, 0.5, 0.08, 0))  # Affects all four figures if don't change agaiin
# par(xaxs="i", yaxs="i")    # Have to define here for hist
par(mgp=c(2.0, 0.5, 0))    # puts axes labels closer I think
par(cex = 0.8)             # With no option all text comes out a bit small

# Each of these plots a panel for one column of dataSumm, showing how
#  they vary with time.
plot(dataSumm$Year, dataSumm$uniqLngtClass, xlab="Year",
     ylab="No. unique length classes", type="o",
     ylim=c(0, max(dataSumm$uniqLngtClass)))
plot(dataSumm$Year, dataSumm$uniqSpec, xlab="Year",
     ylab="No. unique species", type="o", ylim=c(0, max(dataSumm$uniqSpec)))
plot(dataSumm$Year, dataSumm$medNumber, xlab="Year",
     ylab="Median number (per hour)", type="o", ylim=c(0, max(dataSumm$medNumber)))
plot(dataSumm$Year, dataSumm$medBodyMass, xlab="Year",
     ylab="Median body mass (g)", type="o", ylim=c(0, max(dataSumm$medBodyMass)))

dev.off()
@

<<results=tex, echo=FALSE>>=
print(dataSummTab, table.placement="tp", caption.placement="top",
    include.rownames = FALSE) #, sanitize.text.function=function(x){x})  # was !ht
@

Table~\ref{tab:dataSumm} and Figure~\ref{fig:dataSumm} show the data summarised by year.

....Can write text to describe results.....

% ***HERE**There is a clear jump in 2004 of the number of unique length classes, and a gradual increase in the number of unique species identified each year (though with a recent drop). The increase and decline in the median number in each species-specific length class may be of interest (or not), and the jump in median body mass may well be due to the decline in observed species (and it may not be as pronounced when species-specific length-weight conversions get used).


% {\noindent \bf Q1.} Julia, see the above paragraph. We may well need to understand some of this to interpret the final results. I'm hoping you might know about changes in survey protocols, or how comparable the data might be from year-to-year.

\onefig{dataSumm}{Time series of the four columns shown in Table~\ref{tab:dataSumm}. Median number and median body mass are simply based on the species-specific and length-class-specific numbers and body masses, and so can't be easily interpreted for these data.}

\medskip

Only reruns the calculations when the input data changes (the {\tt redo.eight} switch). This code calculates, using my {\tt eightMethods.count()} function, the slope or exponent for each method, plus plots the figure showing the eight methods, all for each year in turn. Any resulting postscript files are huge (because it plots lots of points for the LCD and MLE methods - at least it did for the earlier NSea15 dataset - these may actually be smaller because we're not plotting a point for every fish, but stick with .png for now), so I've changed to {\tt .png} files, which are manageable. % These are in the separate zip file {\tt nSeaFungAnalysis-allYears.7z}, and can be scrolled through one year at a time.

<<doEachYear, echo=FALSE, results=hide>>=

if(redo.eight) {           # Redo method-dependent fits
  fullYears = unique(data$Year)
  fullResults = data.frame()
  for(ii in fullYears)
    {
    eightMethodsRes = eightMethods.count(data = data, oneYear = ii,
        figName = "nSeaFung")
    fullResults = rbind(fullResults, eightMethodsRes)
    # print(paste("Have done ", oneYear))  - can't print in console - try message
    }
}
@

<<plotFig, echo=FALSE, results=hide>>=
# Now need to plot time series with confidence intervals for each method. So
#  eight panels, each of a time series. Like the confPlot ones but sideways.

postscript("nSeaFungTrends.eps", height = figheight, width = figwidth,
           horizontal=FALSE,  paper="special")

par(omi = c(0.14, 0, 0.1, 0.15))      # outer margins in inches
par(mfrow=c(4,2)) #7,1))

oldmai = par("mai")    #   0.6732 0.5412 0.5412 0.2772  inches I think,
                       #    may be indpt of fig size
par(mai=c(0.3, 0.5, 0.08, 0))  # Affects all four figures if don't change agaiin
# par(xaxs="i", yaxs="i")    # Have to define here for hist
par(mgp=c(2.0, 0.5, 0))    # puts axes labels closer I think
par(cex = 0.8)             # With no option all text comes out a bit small
vertThick = 1              # Thickness for vertical lines

# yLim = c(min(fullResults$confMin, na.rm=TRUE),
#     max(fullResults$confMax, na.rm=TRUE))   # -54, 41 due to LT method for
                                              #  original nSea15 dataset.
# Can have common y axis for five methods (after inspecting results):
fullResFive = dplyr::filter(fullResults, Method %in% c("LBmiz", "LBbiom", "LBNbiom",
    "LCD", "MLE"))
yLim = c(min(fullResFive$confMin), max(fullResFive$confMax))

# Each of these plots a panel for one method. Define xLim if the default
#  (integer-based calculation) is not suitable

# No need to return anything from timeSerPlot, did for confPlot because it
#  sorted the multiple confidence intervals from the simulated data.

# Want to use weighted linear regression with weights based on
#  1/(stdErr^2) where stdErr is the standard error of the estimate for b
#  for each year, because the stdErr's have some variability.

trendResults = data.frame()  # Will have one row of trend results for each method

res = timeSerPlot(dplyr::filter(fullResults, Method == "Llin"), legName = "(a) Llin",
            method = "Llin", weightReg=TRUE)
trendResults = rbind(trendResults, res)


res = timeSerPlot(dplyr::filter(fullResults, Method == "LT"), legName = "(b) LT",
            yLab="", method = "LT", weightReg=TRUE)
trendResults = rbind(trendResults, res)

res = timeSerPlot(dplyr::filter(fullResults, Method == "LTplus1"),
    legName = "(c) LTplus1", method = "LTplus1", weightReg=TRUE)
trendResults = rbind(trendResults, res)

res = timeSerPlot(dplyr::filter(fullResults, Method == "LBmiz"), legName = "(d) LBmiz",
            yLim=yLim, yLab="", method = "LBmiz", weightReg=TRUE)
trendResults = rbind(trendResults, res)

res = timeSerPlot(dplyr::filter(fullResults, Method == "LBbiom"),
    legName = "(e) LBbiom", yLim=yLim, method = "LBbiom", weightReg=TRUE)
trendResults = rbind(trendResults, res)

res = timeSerPlot(dplyr::filter(fullResults, Method == "LBNbiom"),
    legName = "(f) LBNbiom", yLim=yLim, yLab="", method = "LBNbiom",
    weightReg=TRUE)
trendResults = rbind(trendResults, res)

res = timeSerPlot(dplyr::filter(fullResults, Method == "LCD"), legName = "(g) LCD",
    yLim=yLim, method = "LCD", weightReg=TRUE)
trendResults = rbind(trendResults, res)

res = timeSerPlot(dplyr::filter(fullResults, Method == "MLE"), legName = "(h) MLE",
    yLim=yLim, yLab="", method = "MLE", legPos = "bottomleft",
    weightReg=TRUE)
trendResults = rbind(trendResults, res)

mtext("Year", side=1, outer=TRUE, line=-0.2, cex=0.8)

dev.off()

trendResultsTab = xtable(dplyr::select(trendResults, -adjRsquared),
  digits=c(0, 0, 4, 4, 4, 2, 2),
  caption="Summary of weighted regression analysis
  of trend through time of the estimated exponent $b$, as estimated using each
  of the eight methods. `Trend' is the estimated annual trend, with
  95\\% confidence intervals given by `Low' and `High';
  p is the p-value for the probability that the trend is significantly
  different to 0, and $R^2$ is the coefficient of determination.
  If $p \\geq 0.05$ then the trend can be considered not
  significantly different to 0. If $p<0.05$ then a negative trend indicates
  a statistically significant decline in the exponent over time, and
  a positive trend indicates a statistically significant increase.",
  lab="tab:trendRes")
@


Figure \ref{fig:nSeaFungTrends} shows the results from using each method in turn to estimate $b$ for each year. A weighted linear regression is fit to the resulting time series of estimates of $b$, to look for any trend (a weighted regression is used because we have estimates of the variance of each estimate of $b$, and these variances do vary between years). Statistical results for the trend analyses are given in Table~\ref{tab:trendRes}.

The results suggest no significant change in $b$ when using three of the methods (namely LT, LTplus1 and MLE) to estimate $b$, yet a significant negative decline when using the remaining five methods. Thus, five methods imply a steepening of the size spectrum over time, whereas three methods imply no change. This demonstrates how methodological differences can lead to differing ecological conclusions.


\onefig{nSeaFungTrends}{For each method in turn, the estimated exponents $b$ (circles) and 95\% confidence intervals (vertical bars) are shown for every year. The fit of a weighted linear regression with 95\% confidence interval is shown as red lines if the trend can be considered statistically significant from 0 ($p<0.05$), and in grey if the trend is not statistically significantly different from 0 ($p \geq 0.05$). The y-axes are the same for (d)-(h). Statistical properties of trends are given in Table~\ref{tab:trendRes}.}

<<results=tex, echo=FALSE>>=
print(trendResultsTab, table.placement="tp", caption.placement="top",
    include.rownames = FALSE, sanitize.text.function=function(x){x})  # was !ht
@

<<exampleData, echo=FALSE, results=hide>>=
# example lines of data, to maybe have as a table in Part 2 manuscript.
egData = data[c(1:6, (dim(data)[1]-5):(dim(data)[1])), ]
egData = mutate(egData, Biomass = Number * bodyMass)
names(egData) = c("Year", "Species", "Length class (cm)", "Number (h$^{-1}$)", "alpha",          "beta", "Body mass (g)", "Total biomass (g)")
egDataTab = xtable(egData, digits=c(0, 0, 0, 0, 3, 4, 4, 2, 2),
  caption="Example data (first six and last six rows) from the ** data set, to demonstrate the information available. Each row represents a unique combination of year, species and length class. `Number' gives the number of individuals (per hour of **trawling) observed for that combination, and can be non-integer because counts of individual fish are scaled by tow duration**. Fish lengths are assigned into length classes, where the value of `Length class' (cm) is the minimum value of the length bin; for this data set fish were usually assigned to 1-cm length classes, and occasionally 0.5~cm. Parameters $\\alpha$ and $\\beta$ are the length-weight coefficients for each particular species, and `Body mass' (g) is the resulting estimated body mass for individuals of that species and length class. `Biomass' (g) is the total biomass of individuals for each row.**TO DO manually: **Change to $\\alpha$ and $\\beta$. Replace SpecCode by actual species name. Add in rows of $\\cdot \\cdot \\cdot$. Manually split column headers over two rows.", lab="tab:egData")  # digits[1] is row.names
@

<<results=tex, echo=FALSE>>=
print(egDataTab, table.placement="tp", caption.placement="top",
    include.rownames = FALSE) #, sanitize.text.function=function(x){x})  # was !ht
# To get particular species names:
# load("ibtsQ1cpuelength.RData")
# dataOrig = tbl_df(q1)
# dplyr::filter(dataOrig, AphiaID == 105814)
# Gives:
# 105814 NS-IBTS 2012       1    3 Sciliorhinus caniculus      340
# 105814 NS-IBTS 1999       1    3  Scyliorhinus canicula      580
# 105814 NS-IBTS 2014       1    5  Scyliorhinus canicula      370
# Great, two names. Go with Scyliorhinus canicula (Smallspotted Catshark
#  [Sharks of the world, Compagno et al.])
# 154675: Lumpenus lampretaeformis  (Snakeblenny)
# 274304: Microchirus variegatus (Thickback SOle

@



<<>>=
postscript("nSeaFungCheck.eps", height = figheight/2, width = figwidth,
           horizontal=FALSE,  paper="special")
plot(dplyr::filter(fullResults, Method=="MLE")$stdErr)
dev.off()
@

\onefig{nSeaFungCheck}{Plotting the standard errors for the MLE method, to check that {\tt bvec} in {\tt eightMethods.count()} is fine enough -- originally had it too coarse which only resulted in about four unique standard errors. ***Check this in other code, just make {\tt bvec} coarser and re-run.}
% data no longer seem to be a table_df   - correct
